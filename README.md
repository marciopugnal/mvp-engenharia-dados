## üìä**MVP ‚Äì Engenharia de Dados para Jogos de Tabuleiro**  
Este projeto aplica conceitos de engenharia de dados para transformar e explorar um dataset de avalia√ß√µes de jogos de tabuleiro em informa√ß√µes estruturadas. O trabalho envolve etapas de ingest√£o, limpeza, transforma√ß√£o, modelagem, armazenamento e an√°lise dos dados. O objetivo √© descobrir rela√ß√µes e comportamentos ocultos, gerando insights que revelem tend√™ncias, fatores de popularidade, padr√µes de comportamento e conex√µes entre jogos e jogadores na comunidade.  

### üé≤ **Dataset**  
O conjunto de dados foi obtido na plataforma Kaggle [fonte: https://www.kaggle.com/datasets/andrewmvd/board-games] e re√∫ne informa√ß√µes extra√≠das do site BoardGameGeek (BGG), uma das maiores comunidades online dedicadas a jogos de tabuleiro, contendo informa√ß√µes detalhadas sobre jogos, avalia√ß√µes, mec√¢nicas, categorias e perfis de jogadores.  

### ‚òÅÔ∏è **Plataforma**  
O projeto utiliza o Databricks (Free Edition) como plataforma Lakehouse, integrando camadas de Data Lake e Data Warehouse em uma arquitetura unificada. Esse ambiente permite orquestrar pipelines de ingest√£o, processamento distribu√≠do e consultas anal√≠ticas utilizando Python, SQL e PySpark, garantindo escalabilidade, paralelismo e governan√ßa dos dados.  

### ‚ùì **Quest√µes anal√≠ticas a serem respondidas**  
Com o intuito de atingir os objetivos definidos, este trabalho se dedicar√° a responder quest√µes como:  
‚ñ∂ Top 10 jogos mais bem avaliados e sua rela√ß√£o com popularidade;  
‚ñ∂ Influ√™ncia da complexidade nas avalia√ß√µes;  
‚ñ∂ Mec√¢nicas e categorias mais associadas a alta popularidade;  
‚ñ∂ Correla√ß√£o entre complexidade, tempo de jogo e satisfa√ß√£o; e  
‚ñ∂ Perfil dos jogos por n√∫mero de jogadores e faixa et√°ria recomendada.  

üìå **Nota:** _As respostas est√£o consolidadas, evidenciadas e registradas nos arquivos abaixo, ambos armazenados no GitHub:_  
‚ñ∂ **Relatorio-Final**  
--->  xxxxxx
‚ñ∂ **Query-Tabuleiro-Questoes-Solucoes**  
---> https://github.com/marciopugnal/mvp-engenharia-dados/blob/main/Query-Tabuleiro-Questoes-Solucoes.ipynb  

‚ñ∂ **Painel‚ÄëJogos‚ÄëTabuleiro**  
---> https://github.com/marciopugnal/mvp-engenharia-dados/blob/main/Painel-Jogos-Tabuleiro-v.2025-12-07.pdf  

‚ñ∂ **Notebook‚ÄëMVP‚ÄëEng‚ÄëDados‚ÄëTabuleiro**  
--->  https://github.com/marciopugnal/mvp-engenharia-dados/blob/main/Query-Tabuleiro.ipynb  

### üß© **Metodologia**  
A abordagem ser√° organizada em etapas sequenciais, estruturadas em um pipeline de dados:  
‚ñ∂ Ingest√£o de dados: coleta de informa√ß√µes a partir de um dataset armazenado no GitHub;  
‚ñ∂ Transforma√ß√£o: limpeza, padroniza√ß√£o e enriquecimento dos dados, assegurando consist√™ncia e qualidade;  
‚ñ∂ Modelagem: aplica√ß√£o do modelo estrela, com a defini√ß√£o de tabelas de fatos e dimens√µes;  
‚ñ∂ Armazenamento: consolida√ß√£o em um data lake estruturado no Databricks, preparado para consultas e an√°lises; e  
‚ñ∂ An√°lise explorat√≥ria: utiliza√ß√£o de SQL, Python e PySpark para consulta de banco de dados e gera√ß√£o de relat√≥rios e gr√°ficos para identificar padr√µes, tend√™ncias e fatores que influenciam o desempenho e a popularidade dos jogos.  

### üõ†Ô∏è **Ferramentas**  
‚ñ∂ Linguagens: Python, SQL  
‚ñ∂ Bibliotecas: Pandas, NumPy, PySpark  
‚ñ∂ Ambientes: Databricks, GitHub, brModelo  
‚ñ∂ Documenta√ß√£o: Markdown e Cat√°logo Databricks  

### üìù **Resultados Esperados**  
‚ñ∂ Identifica√ß√£o de padr√µes entre jogos e jogadores;  
‚ñ∂ Segmenta√ß√£o por caracter√≠sticas e popularidade;  
‚ñ∂ Correla√ß√µes entre mec√¢nicas, categorias e avalia√ß√µes;  
‚ñ∂ Tend√™ncias de comportamento da comunidade;  
‚ñ∂ Perfis de jogadores baseados em prefer√™ncias e avalia√ß√µes;  
  
### ‚úÖ **Autoavalia√ß√£o**  
O desenvolvimento deste trabalho possibilitou aplicar, na pr√°tica, alguns dos conhecimentos te√≥ricos das disciplinas, consolidando o entendimento dos conceitos de engenharia de dados dentro do contexto da ci√™ncia de dados. A experi√™ncia com bancos de dados e SQL foi essencial para modelar estruturas, executar consultas e gerar insights por meio de filtragens, agrega√ß√µes e c√°lculos anal√≠ticos.  
No in√≠cio, surgiram desafios relacionados ao uso do Databricks, √† curva de aprendizado do PySpark e √† necessidade de consultar documenta√ß√µes, ferramentas de IA, tutoriais e v√≠deos. Tamb√©m houve dificuldades na integra√ß√£o com o GitHub e na compreens√£o dos recursos do Spark SQL, exigindo experimenta√ß√£o e estudo cont√≠nuo.  
Para trabalhos futuros, recomenda-se o aprofundamento das an√°lises, a incorpora√ß√£o de novos conjuntos de dados, a possibilidade de organiza√ß√£o em camadas e a implementa√ß√£o de t√©cnicas de machine learning, de modo a viabilizar investiga√ß√µes mais automatizadas, robustas, e metodologicamente avan√ßadas.
